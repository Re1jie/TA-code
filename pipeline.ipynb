{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38ac1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "from caoa_solver import run_priority_simulation\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c431dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Files\n",
    "input = 'split_by_month/Voyage_Data_2025_07.csv'\n",
    "output = 'results_file/current/optimized_schedule.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "87c8c38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menjalankan Simulasi Baseline (First-Come-First-Served)...\n",
      "Total Waiting Time: 35011.00 Jam\n",
      "\n",
      "Top 30 Antrean Terparah:\n",
      "                Ship           Port         Planned_ETA  Delay_Hours\n",
      "81        KM LABOBAR  TANJUNG PRIOK 2025-06-02 19:00:00       1411.0\n",
      "106  KM GUNUNG DEMPO  TANJUNG PRIOK 2025-06-04 05:00:00       1395.0\n",
      "141         KM WILIS       MAKASSAR 2025-06-06 00:00:00       1359.0\n",
      "381       KM SIRIMAU       MAKASSAR 2025-06-16 13:00:00       1219.0\n",
      "620      KM SANGIANG          AMBON 2025-06-26 15:00:00       1058.0\n",
      "3       KM DOBONSOLO  TANJUNG PRIOK 2025-05-24 16:00:00       1032.0\n",
      "9        KM KELIMUTU  TANJUNG PRIOK 2025-05-27 10:00:00       1004.0\n",
      "8         KM CIREMAI  TANJUNG PRIOK 2025-05-26 20:00:00        989.0\n",
      "23        KM BK RAYA  TANJUNG PRIOK 2025-05-29 17:00:00        974.0\n",
      "19       KM NGGAPULU  TANJUNG PRIOK 2025-05-29 03:00:00        973.0\n",
      "27          KM KELUD  TANJUNG PRIOK 2025-05-30 04:00:00        970.0\n",
      "11        KM LAMBELU       MAKASSAR 2025-05-27 21:00:00        970.0\n",
      "41   KM BK SIGUNTANG  TANJUNG PRIOK 2025-05-31 13:00:00        954.0\n",
      "16      KM DOROLONDA       SURABAYA 2025-05-28 19:00:00        945.0\n",
      "45            KM AWU       SURABAYA 2025-05-31 18:00:00        929.0\n",
      "46   KM TILONGKABILA       MAKASSAR 2025-05-31 18:00:00        909.0\n",
      "74       KM JETLINER        KENDARI 2025-06-02 11:00:00        881.0\n",
      "98           KM EGON       SURABAYA 2025-06-03 19:00:00        867.0\n",
      "75     KM TATAMAILAU         SORONG 2025-06-02 12:00:00        840.0\n",
      "128     KM PANGRANGO          AMBON 2025-06-05 12:00:00        826.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "def load_data():\n",
    "    ports_df = pd.read_csv('port_data.csv')\n",
    "    voyages_df = pd.read_csv(input)\n",
    "    \n",
    "    # Konversi string tanggal ke datetime object\n",
    "    voyages_df['ETA_Planned'] = pd.to_datetime(voyages_df['ETA_Planned'])\n",
    "    \n",
    "    # Buat Dictionary Kapasitas Pelabuhan: {'TANJUNG PRIOK': 3, 'SURABAYA': 2, ...}\n",
    "    port_capacity = dict(zip(ports_df['Nama_Pelabuhan'], ports_df['Total_Berths']))\n",
    "    \n",
    "    return voyages_df, port_capacity\n",
    "\n",
    "# 2. Kelas untuk Melacak Status Pelabuhan\n",
    "class PortManager:\n",
    "    def __init__(self, capacity_dict):\n",
    "        # Menyimpan timeline kapan berth kosong\n",
    "        # Format: {'PRIOK': [waktu_bebas_berth_1, waktu_bebas_berth_2, ...]}\n",
    "        self.berths = {p: [pd.Timestamp.min] * cap for p, cap in capacity_dict.items()}\n",
    "        \n",
    "    def request_berthing(self, port_name, arrival_time, service_duration):\n",
    "        if port_name not in self.berths:\n",
    "            # Jika pelabuhan tidak ada di data kapasitas, asumsikan 1 berth\n",
    "            self.berths[port_name] = [pd.Timestamp.min]\n",
    "            \n",
    "        available_slots = self.berths[port_name]\n",
    "        available_slots.sort() # Urutkan dari yang paling cepat kosong\n",
    "        \n",
    "        # Ambil slot yang paling cepat kosong\n",
    "        earliest_free_time = available_slots[0]\n",
    "        \n",
    "        # Hitung waktu sandar aktual (RTA - Realized Time of Arrival)\n",
    "        # Kapal bisa masuk max(Jadwal Kedatangan, Waktu Berth Kosong)\n",
    "        actual_berthing_time = max(arrival_time, earliest_free_time)\n",
    "        \n",
    "        # Hitung Delay (Antrean)\n",
    "        waiting_time = (actual_berthing_time - arrival_time).total_seconds() / 3600.0\n",
    "        \n",
    "        # Update kapan berth ini akan kosong lagi (ETD)\n",
    "        departure_time = actual_berthing_time + timedelta(hours=service_duration)\n",
    "        available_slots[0] = departure_time # Kunci slot ini sampai kapal pergi\n",
    "        \n",
    "        return actual_berthing_time, departure_time, waiting_time\n",
    "\n",
    "# 3. Fungsi Simulasi Utama (Decoder)\n",
    "def run_simulation(voyages_df, port_capacity):\n",
    "    # Urutkan seluruh jadwal berdasarkan ETA Planned (Kronologis)\n",
    "    # Ini logika FCFS murni (Siapa cepat dia dapat)\n",
    "    queue = voyages_df.sort_values('ETA_Planned').copy()\n",
    "    \n",
    "    manager = PortManager(port_capacity)\n",
    "    \n",
    "    results = []\n",
    "    total_system_delay = 0\n",
    "    \n",
    "    # Dictionary untuk melacak kapan kapal selesai di pelabuhan sebelumnya\n",
    "    # Agar delay terpropagasi ke pelabuhan berikutnya\n",
    "    ship_availability = {} \n",
    "    \n",
    "    for idx, row in queue.iterrows():\n",
    "        ship = row['Ship_Name']\n",
    "        port = row['Port_Name']\n",
    "        planned_eta = row['ETA_Planned']\n",
    "        duration = row['Service_Time_Hours']\n",
    "        \n",
    "        # Cek ketersediaan kapal (Propagasi Delay)\n",
    "        # Kapal tidak bisa tiba di pelabuhan B sebelum selesai dari pelabuhan A + Sailing Time\n",
    "        # (Sailing time disederhanakan/diabaikan dulu di snippet ini, \n",
    "        # asumsinya ETA_Planned sudah termasuk sailing time ideal)\n",
    "        \n",
    "        if ship in ship_availability:\n",
    "            # Jika kapal telat di pelabuhan sebelumnya, ETA di sini juga mundur\n",
    "            prev_departure = ship_availability[ship]\n",
    "            # Estimasi sailing time dari data asli (selisih ETA port ini dgn departure port lalu)\n",
    "            # Untuk simplifikasi FCFS awal, kita pakai max(Planned, Prev_Departure + Sailing)\n",
    "            # Di sini kita paksa kapal minimal tiba sesuai planned, atau setelah free dari port lalu\n",
    "            current_arrival_candidate = max(planned_eta, prev_departure) \n",
    "        else:\n",
    "            current_arrival_candidate = planned_eta\n",
    "            \n",
    "        # Minta akses ke Pelabuhan\n",
    "        rta, etd, wait = manager.request_berthing(port, current_arrival_candidate, duration)\n",
    "        \n",
    "        # Simpan hasil\n",
    "        total_system_delay += wait\n",
    "        ship_availability[ship] = etd # Kapal baru bebas setelah ETD\n",
    "        \n",
    "        results.append({\n",
    "            'Ship': ship,\n",
    "            'Port': port,\n",
    "            'Planned_ETA': planned_eta,\n",
    "            'Actual_RTA': rta,\n",
    "            'Actual_ETD': etd,\n",
    "            'Delay_Hours': wait\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results), total_system_delay\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    df, caps = load_data()\n",
    "    print(\"Menjalankan Simulasi Baseline (First-Come-First-Served)...\")\n",
    "    res_df, total_delay = run_simulation(df, caps)\n",
    "    \n",
    "    print(f\"Total Waiting Time: {total_delay:.2f} Jam\")\n",
    "    print(\"\\nTop 30 Antrean Terparah:\")\n",
    "    print(res_df.sort_values('Delay_Hours', ascending=False).head(20)[['Ship', 'Port', 'Planned_ETA', 'Delay_Hours']])\n",
    "    \n",
    "    res_df.to_csv('results_file/current/baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eca6176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menghitung fitness awal menggunakan 12 CPU Cores...\n",
      "Start Optimization. Initial Best Delay: 765067.00 Hours\n",
      "Iterasi 1: REKOR BARU! Delay turun ke 759950.00 Jam\n",
      "Iterasi 3: REKOR BARU! Delay turun ke 758857.00 Jam\n",
      "Iterasi 4: REKOR BARU! Delay turun ke 757098.00 Jam\n",
      "Iterasi 6: REKOR BARU! Delay turun ke 756162.00 Jam\n",
      "Iterasi 9: REKOR BARU! Delay turun ke 756078.00 Jam\n",
      "Iterasi 10: REKOR BARU! Delay turun ke 755844.00 Jam\n",
      "Iterasi 10/200 | Best: 755844.00 h | Avg: 758957.78 h | Depleted: 0\n",
      "Iterasi 12: REKOR BARU! Delay turun ke 755426.00 Jam\n",
      "Iterasi 17: REKOR BARU! Delay turun ke 754748.00 Jam\n",
      "Iterasi 20/200 | Best: 754748.00 h | Avg: 756284.59 h | Depleted: 0\n",
      "Iterasi 22: REKOR BARU! Delay turun ke 754335.00 Jam\n",
      "Iterasi 25: REKOR BARU! Delay turun ke 754292.00 Jam\n",
      "Iterasi 26: REKOR BARU! Delay turun ke 754173.00 Jam\n",
      "Iterasi 30/200 | Best: 754173.00 h | Avg: 755559.63 h | Depleted: 0\n",
      "Iterasi 32: REKOR BARU! Delay turun ke 754138.00 Jam\n",
      "Iterasi 35: REKOR BARU! Delay turun ke 754114.00 Jam\n",
      "Iterasi 37: REKOR BARU! Delay turun ke 753842.00 Jam\n",
      "Iterasi 40: REKOR BARU! Delay turun ke 753706.00 Jam\n",
      "Iterasi 40/200 | Best: 753706.00 h | Avg: 755025.67 h | Depleted: 0\n",
      "Iterasi 50/200 | Best: 753706.00 h | Avg: 754516.89 h | Depleted: 0\n",
      "Iterasi 55: REKOR BARU! Delay turun ke 753670.00 Jam\n",
      "Iterasi 60/200 | Best: 753670.00 h | Avg: 754284.71 h | Depleted: 0\n",
      "Iterasi 65: REKOR BARU! Delay turun ke 753611.00 Jam\n",
      "Iterasi 68: REKOR BARU! Delay turun ke 753414.00 Jam\n",
      "Iterasi 70/200 | Best: 753414.00 h | Avg: 754085.04 h | Depleted: 0\n",
      "Iterasi 73: REKOR BARU! Delay turun ke 753407.00 Jam\n",
      "Iterasi 77: REKOR BARU! Delay turun ke 753405.00 Jam\n",
      "Iterasi 80/200 | Best: 753405.00 h | Avg: 753905.86 h | Depleted: 0\n",
      "Iterasi 81: REKOR BARU! Delay turun ke 753311.00 Jam\n",
      "Iterasi 86: REKOR BARU! Delay turun ke 753280.00 Jam\n",
      "Iterasi 90/200 | Best: 753280.00 h | Avg: 753794.11 h | Depleted: 0\n",
      "Iterasi 100/200 | Best: 753280.00 h | Avg: 753688.32 h | Depleted: 0\n",
      "Iterasi 104: REKOR BARU! Delay turun ke 753267.00 Jam\n",
      "Iterasi 105: REKOR BARU! Delay turun ke 753213.00 Jam\n",
      "Iterasi 110/200 | Best: 753213.00 h | Avg: 753583.34 h | Depleted: 0\n",
      "Iterasi 111: REKOR BARU! Delay turun ke 753090.00 Jam\n",
      "Iterasi 115: REKOR BARU! Delay turun ke 753052.00 Jam\n",
      "Iterasi 120/200 | Best: 753052.00 h | Avg: 753527.20 h | Depleted: 0\n",
      "Iterasi 130/200 | Best: 753052.00 h | Avg: 753486.99 h | Depleted: 0\n",
      "Iterasi 140: REKOR BARU! Delay turun ke 753028.00 Jam\n",
      "Iterasi 140/200 | Best: 753028.00 h | Avg: 753459.84 h | Depleted: 0\n",
      "Iterasi 150/200 | Best: 753028.00 h | Avg: 753421.43 h | Depleted: 0\n",
      "Iterasi 153: REKOR BARU! Delay turun ke 752837.00 Jam\n",
      "Iterasi 160/200 | Best: 752837.00 h | Avg: 753385.73 h | Depleted: 0\n",
      "Iterasi 170/200 | Best: 752837.00 h | Avg: 753354.63 h | Depleted: 0\n",
      "Iterasi 180/200 | Best: 752837.00 h | Avg: 753336.14 h | Depleted: 0\n",
      "Iterasi 190/200 | Best: 752837.00 h | Avg: 753309.73 h | Depleted: 0\n",
      "Iterasi 200/200 | Best: 752837.00 h | Avg: 753287.07 h | Depleted: 0\n",
      "Selesai.\n"
     ]
    }
   ],
   "source": [
    "# ParallelCAOA\n",
    "class ParallelCAOA:\n",
    "    def __init__(self, data_file, port_file, \n",
    "                 pop_size=50, max_iter=100,\n",
    "                 alpha=0.3, beta=0.1, gamma=1.0, delta=1e-4, initial_energy=10.0,\n",
    "                 n_jobs=-1): # n_jobs = -1 artinya pakai SEMUA core CPU\n",
    "        \n",
    "        # --- 1. Load Data (Hanya sekali di awal) ---\n",
    "        self.voyages = pd.read_csv(data_file)\n",
    "        self.voyages['ETA_Planned'] = pd.to_datetime(self.voyages['ETA_Planned'])\n",
    "        \n",
    "        ports = pd.read_csv(port_file)\n",
    "        self.port_caps = dict(zip(ports['Nama_Pelabuhan'], ports['Total_Berths']))\n",
    "        \n",
    "        # --- Parameter CAOA ---\n",
    "        self.dim = len(self.voyages)\n",
    "        self.pop_size = pop_size\n",
    "        self.max_iter = max_iter\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.delta = delta\n",
    "        self.init_energy = initial_energy\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        self.lb = 0.0\n",
    "        self.ub = 1.0\n",
    "\n",
    "    def calculate_fitness_batch(self, population):\n",
    "        \"\"\"\n",
    "        Menghitung fitness untuk seluruh populasi secara PARALEL.\n",
    "        \"\"\"\n",
    "        # joblib akan menyebar tugas ini ke seluruh core CPU\n",
    "        results = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(run_priority_simulation)(self.voyages, self.port_caps, ind) \n",
    "            for ind in population\n",
    "        )\n",
    "        return np.array(results)\n",
    "\n",
    "    def optimize(self):\n",
    "        # Inisialisasi\n",
    "        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n",
    "        population[0] = 0.5\n",
    "        energies = np.full(self.pop_size, self.init_energy)\n",
    "        \n",
    "        print(f\"Menghitung fitness awal menggunakan {multiprocessing.cpu_count()} CPU Cores...\")\n",
    "        fitness = self.calculate_fitness_batch(population)\n",
    "        \n",
    "        # Cari Global Best\n",
    "        best_idx = np.argmin(fitness)\n",
    "        gBestScore = fitness[best_idx]\n",
    "        gBestPos = population[best_idx].copy()\n",
    "        \n",
    "        print(f\"Start Optimization. Initial Best Delay: {gBestScore:.2f} Hours\")\n",
    "        \n",
    "        # --- MAIN LOOP ---\n",
    "        for t in range(self.max_iter):\n",
    "            old_positions = population.copy()\n",
    "            old_fitness = fitness.copy()\n",
    "            \n",
    "            # --- 1. UPDATE POSISI (Vektorisasi - Cepat di Numpy) ---\n",
    "            # Kita bisa update posisi semua buaya sekaligus tanpa loop\n",
    "            r = np.random.random((self.pop_size, self.dim))\n",
    "            \n",
    "            # Matriks Leader (di-broadcast ke semua baris)\n",
    "            leader_matrix = np.tile(gBestPos, (self.pop_size, 1))\n",
    "            \n",
    "            # Rumus Gerak CAOA (Vectorized)\n",
    "            # X_new = X + alpha*(Leader - X) + beta*(1 - 2*r)\n",
    "            movements = self.alpha * (leader_matrix - population) + \\\n",
    "                        self.beta * (1.0 - 2.0 * r)\n",
    "            \n",
    "            new_population = population + movements\n",
    "            new_population = np.clip(new_population, self.lb, self.ub)\n",
    "            \n",
    "            # --- 2. EVALUASI FITNESS PARALEL (Bottleneck Solver) ---\n",
    "            # Ini bagian yang biasanya lambat, sekarang dikebut pakai semua core\n",
    "            new_fitness = self.calculate_fitness_batch(new_population)\n",
    "            \n",
    "            # --- 3. SELEKSI (Vectorized) ---\n",
    "            # Cari mana yang lebih baik\n",
    "            improved_mask = new_fitness < fitness\n",
    "            # Terapkan delta threshold (opsional, simplifikasi disini)\n",
    "            \n",
    "            # Update Populasi & Fitness hanya jika lebih baik\n",
    "            population[improved_mask] = new_population[improved_mask]\n",
    "            fitness[improved_mask] = new_fitness[improved_mask]\n",
    "            \n",
    "            # Update Global Best\n",
    "            current_best_idx = np.argmin(fitness)\n",
    "            if fitness[current_best_idx] < gBestScore:\n",
    "                gBestScore = fitness[current_best_idx]\n",
    "                gBestPos = population[current_best_idx].copy()\n",
    "                print(f\"Iterasi {t+1}: REKOR BARU! Delay turun ke {gBestScore:.2f} Jam\")\n",
    "\n",
    "            # --- 4. ENERGY MECHANISM ---\n",
    "            distances = np.sqrt(np.sum((population - old_positions)**2, axis=1))\n",
    "            energies = energies - (self.gamma * distances)\n",
    "            \n",
    "            # Reset Depleted\n",
    "            depleted_indices = np.where(energies <= 0)[0]\n",
    "            if len(depleted_indices) > 0:\n",
    "                # Respawn acak\n",
    "                population[depleted_indices] = np.random.uniform(\n",
    "                    self.lb, self.ub, (len(depleted_indices), self.dim)\n",
    "                )\n",
    "                energies[depleted_indices] = self.init_energy\n",
    "                \n",
    "                # Hitung fitness untuk yang baru respawn (Paralel parsial)\n",
    "                # Kita bisa hitung ini di iterasi depan, atau hitung sekarang.\n",
    "                # Agar akurat, hitung sekarang:\n",
    "                respawn_fits = Parallel(n_jobs=self.n_jobs)(\n",
    "                    delayed(run_priority_simulation)(self.voyages, self.port_caps, population[i])\n",
    "                    for i in depleted_indices\n",
    "                )\n",
    "                fitness[depleted_indices] = np.array(respawn_fits)\n",
    "\n",
    "            # Logging\n",
    "            if (t+1) % 10 == 0:\n",
    "                print(f\"Iterasi {t+1}/{self.max_iter} | Best: {gBestScore:.2f} h | Avg: {np.mean(fitness):.2f} h | Depleted: {len(depleted_indices)}\")\n",
    "\n",
    "        return gBestPos, gBestScore\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Settings untuk Big Data\n",
    "    optimizer = ParallelCAOA(\n",
    "        data_file=input, # Ganti dengan data besar Anda\n",
    "        port_file='port_data.csv',\n",
    "        pop_size=100,      # Bisa naikkan populasi karena lebih cepat\n",
    "        max_iter=200,\n",
    "        alpha=0.3, beta=0.2, gamma=0.1, initial_energy=50.0,\n",
    "        n_jobs=-1          # -1 = Pakai Semua Core CPU\n",
    "    )\n",
    "    \n",
    "    best_prio, min_delay = optimizer.optimize()\n",
    "    \n",
    "    # Simpan Hasil\n",
    "    df_result = optimizer.voyages.copy()\n",
    "    df_result['Optimized_Priority'] = best_prio\n",
    "    df_result.to_csv(output, index=False)\n",
    "    print(\"Selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18786312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEMULAI PERHITUNGAN METRIK (INDEX MERGE) ===\n",
      "✅ Validasi Sukses: Kedua file memiliki 733 baris.\n",
      "Menggabungkan data prioritas berdasarkan index...\n",
      "1. Menghitung Baseline (FCFS)...\n",
      "2. Menghitung Optimized (CAOA)...\n",
      "\n",
      "=============================================\n",
      "METRIK               | NILAI               \n",
      "---------------------------------------------\n",
      "Total Delay Baseline : 776,477.00 Jam\n",
      "Total Delay Optimized : 752,837.00 Jam\n",
      "---------------------------------------------\n",
      "Time Saved           : 23,640.00 Jam\n",
      "Efficiency Gain      : 3.04%\n",
      "=============================================\n",
      "Laporan detail disimpan ke: results_file/current/final_detailed_report.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Pastikan file caoa_solver.py ada di folder yang sama\n",
    "from caoa_solver import run_priority_simulation \n",
    "\n",
    "def generate_metrics_report(voyage_file, port_file, optimized_file):\n",
    "    print(\"=== MEMULAI PERHITUNGAN METRIK (INDEX MERGE) ===\")\n",
    "    \n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        voyages = pd.read_csv(voyage_file)\n",
    "        ports = pd.read_csv(port_file)\n",
    "        optimized_data = pd.read_csv(optimized_file)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ ERROR: File tidak ditemukan - {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. VALIDASI JUMLAH BARIS (Syarat Wajib Index Merge)\n",
    "    if len(voyages) != len(optimized_data):\n",
    "        print(f\"❌ FATAL ERROR: Jumlah baris tidak sama!\")\n",
    "        print(f\"   Input: {len(voyages)} vs Output: {len(optimized_data)}\")\n",
    "        print(\"   Tidak bisa melakukan merge by index karena struktur data berubah.\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"✅ Validasi Sukses: Kedua file memiliki {len(voyages)} baris.\")\n",
    "\n",
    "    # 3. MERGING BY INDEX (Direct Assignment)\n",
    "    # Kita tidak pakai pd.merge(). Kita langsung tempel kolomnya.\n",
    "    # Asumsinya baris ke-1 di input adalah baris ke-1 di output.\n",
    "    print(\"Menggabungkan data prioritas berdasarkan index...\")\n",
    "    \n",
    "    merged_df = voyages.copy()\n",
    "    \n",
    "    # Pre-process datetime untuk simulasi\n",
    "    merged_df['ETA_Planned'] = pd.to_datetime(merged_df['ETA_Planned'])\n",
    "    \n",
    "    # TEMPEL KOLOM PRIORITAS\n",
    "    # Ini adalah inti perbaikannya.\n",
    "    merged_df['Optimized_Priority'] = optimized_data['Optimized_Priority']\n",
    "    \n",
    "    # Isi NaN dengan 0.5 (Safety)\n",
    "    merged_df['Optimized_Priority'] = merged_df['Optimized_Priority'].fillna(0.5)\n",
    "\n",
    "    # Setup Kapasitas Pelabuhan\n",
    "    caps = dict(zip(ports['Nama_Pelabuhan'], ports['Total_Berths']))\n",
    "\n",
    "    # 4. RUN SIMULASI VIA CAOA_SOLVER\n",
    "    \n",
    "    # A. Baseline (FCFS -> Priority semua 0.5)\n",
    "    print(\"1. Menghitung Baseline (FCFS)...\")\n",
    "    baseline_prio = [0.5] * len(merged_df)\n",
    "    # Gunakan merged_df yang sudah bersih\n",
    "    df_baseline = run_priority_simulation(merged_df, caps, baseline_prio, return_detailed=True)\n",
    "    \n",
    "    # B. Optimized (CAOA)\n",
    "    print(\"2. Menghitung Optimized (CAOA)...\")\n",
    "    opt_prio = merged_df['Optimized_Priority'].values\n",
    "    df_optimized = run_priority_simulation(merged_df, caps, opt_prio, return_detailed=True)\n",
    "    \n",
    "    # 5. Hitung Statistik\n",
    "    total_delay_base = df_baseline['Delay_Hours'].sum()\n",
    "    total_delay_opt = df_optimized['Delay_Hours'].sum()\n",
    "    \n",
    "    # Hitung Delta\n",
    "    time_saved = total_delay_base - total_delay_opt\n",
    "    efficiency_gain = (time_saved / total_delay_base) * 100 if total_delay_base > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*45)\n",
    "    print(f\"{'METRIK':<20} | {'NILAI':<20}\")\n",
    "    print(\"-\" * 45)\n",
    "    print(f\"{'Total Delay Baseline':<20} : {total_delay_base:,.2f} Jam\")\n",
    "    print(f\"{'Total Delay Optimized':<20} : {total_delay_opt:,.2f} Jam\")\n",
    "    print(\"-\" * 45)\n",
    "    print(f\"{'Time Saved':<20} : {time_saved:,.2f} Jam\")\n",
    "    print(f\"{'Efficiency Gain':<20} : {efficiency_gain:.2f}%\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # Simpan file detail\n",
    "    output_detail = 'results_file/current/final_detailed_report.csv'\n",
    "    df_optimized.to_csv(output_detail, index=False)\n",
    "    print(f\"Laporan detail disimpan ke: {output_detail}\")\n",
    "\n",
    "# --- EKSEKUSI LANGSUNG ---\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Menggunakan variabel global 'input' dan 'output' dari cell sebelumnya\n",
    "        input_file = input \n",
    "        output_file = output \n",
    "        port_file = 'port_data.csv'\n",
    "        \n",
    "        generate_metrics_report(input_file, port_file, output_file)\n",
    "        \n",
    "    except NameError:\n",
    "        print(\"⚠️ Variabel 'input' atau 'output' belum didefinisikan.\")\n",
    "        # Uncomment baris di bawah ini untuk testing manual jika variabel global tidak ada\n",
    "        # input_file = 'split_by_month/Voyage_Data_2025_01.csv'\n",
    "        # output_file = 'results_file/current/optimized_schedule.csv'\n",
    "        # generate_metrics_report(input_file, 'port_data.csv', output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
