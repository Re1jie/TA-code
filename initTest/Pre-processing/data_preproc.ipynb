{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a69acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28daa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Membaca file: testcase.csv ---\n",
      "Ditemukan 73 pelabuhan unik.\n",
      "\n",
      "Daftar Pelabuhan:\n",
      "1. Agats\n",
      "2. Ambon\n",
      "3. Awerange\n",
      "4. Bacan\n",
      "5. Balikpapan\n",
      "6. Banda\n",
      "7. Banggai\n",
      "8. Batam\n",
      "9. Batulicin\n",
      "10. Bau-Bau\n",
      "11. Belawan\n",
      "12. Benoa\n",
      "13. Biak\n",
      "14. Bima\n",
      "15. Bitung\n",
      "16. Blinyu\n",
      "17. Bontang\n",
      "18. Cirebon\n",
      "19. Dobo\n",
      "20. Ende\n",
      "21. Fak-Fak\n",
      "22. Geser\n",
      "23. Gorontalo\n",
      "24. Jayapura\n",
      "25. Kaimana\n",
      "26. Kalabahi\n",
      "27. Karimun Jawa\n",
      "28. Kendari\n",
      "29. Kijang\n",
      "30. Kumai\n",
      "31. Kupang\n",
      "32. Labuan Bajo\n",
      "33. Larantuka\n",
      "34. Lembar\n",
      "35. Letung\n",
      "36. Lewoleba\n",
      "37. Luwuk\n",
      "38. Makassar\n",
      "39. Manokwari\n",
      "40. Maumere\n",
      "41. Merauke\n",
      "42. Midai\n",
      "43. Nabire\n",
      "44. Namlea\n",
      "45. Namrole\n",
      "46. Natuna\n",
      "47. Nunukan\n",
      "48. Pantoloan\n",
      "49. Pare-Pare\n",
      "50. Pontianak\n",
      "51. Raha\n",
      "52. Rote\n",
      "53. Sampit\n",
      "54. Sanana\n",
      "55. Saumlaki\n",
      "56. Semarang\n",
      "57. Serasan\n",
      "58. Serui\n",
      "59. Sorong\n",
      "60. Surabaya\n",
      "61. Tarakan\n",
      "62. Tarempa\n",
      "63. Ternate\n",
      "64. Tg. Balai Karimun\n",
      "65. Tg. Pandan\n",
      "66. Tg. Priok\n",
      "67. Tidore\n",
      "68. Timika\n",
      "69. Tual\n",
      "70. Waikelo\n",
      "71. Waingapu\n",
      "72. Wanci\n",
      "73. Waren\n"
     ]
    }
   ],
   "source": [
    "def get_unique_ports_pipeline(file_path):\n",
    "    print(f\"--- Membaca file: {file_path} ---\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    raw_ports = df['PELABUHAN'].astype(str).str.strip()\n",
    "    unique_ports = raw_ports.unique()\n",
    "    unique_ports.sort()\n",
    "    \n",
    "    count = len(unique_ports)\n",
    "\n",
    "    print(f\"Ditemukan {count} pelabuhan unik.\")\n",
    "    print(\"\\nDaftar Pelabuhan:\")\n",
    "    for i, port in enumerate(unique_ports):\n",
    "        print(f\"{i+1}. {port}\")\n",
    "        \n",
    "    return unique_ports, count\n",
    "\n",
    "file_path = '/home/re1jie/TA-code/JSSP-CAOA-SSR/Data/testcase.csv'\n",
    "\n",
    "ports_list, total_ports = get_unique_ports_pipeline(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a97a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tersimpan di jssp_tardiness_data.csv dengan kolom Due_Date.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_jssp_tardiness(file_path, output_path='jssp_tardiness_data.csv'):\n",
    "    # 1. Load & Parse\n",
    "    df = pd.read_csv(file_path, dtype={'VOYAGE': str})\n",
    "    \n",
    "    def parse_dt(d, t):\n",
    "        if pd.isna(d) or pd.isna(t): return pd.NaT\n",
    "        return datetime.strptime(f\"{d} {t}\", \"%d-%b-%y %H:%M\")\n",
    "\n",
    "    df['ETA_FULL'] = df.apply(lambda x: parse_dt(x['ETA_TANGGAL'], x['ETA_JAM']), axis=1)\n",
    "    df['ETD_FULL'] = df.apply(lambda x: parse_dt(x['ETD_TANGGAL'], x['ETD_JAM']), axis=1)\n",
    "    df = df.dropna(subset=['ETA_FULL']).sort_values('ETA_FULL')\n",
    "\n",
    "    # 2. Mappings\n",
    "    unique_ports = sorted(df['PELABUHAN'].unique())\n",
    "    port_map = {p: i+1 for i, p in enumerate(unique_ports)}\n",
    "    df['Machine_ID'] = df['PELABUHAN'].map(port_map)\n",
    "    \n",
    "    df['JOB_KEY'] = df['NAMA_KAPAL'] + \"_\" + df['VOYAGE']\n",
    "    unique_jobs = df['JOB_KEY'].unique()\n",
    "    job_map = {k: i+1 for i, k in enumerate(unique_jobs)}\n",
    "    \n",
    "    # 3. Time Reference (t=0)\n",
    "    global_start = df['ETA_FULL'].min()\n",
    "    \n",
    "    jssp_rows = []\n",
    "    \n",
    "    for job_key, group in df.groupby('JOB_KEY'):\n",
    "        group = group.sort_values('ETA_FULL')\n",
    "        seq = 1\n",
    "        for idx, row in group.iterrows():\n",
    "            # Arrival Time (Ready Time)\n",
    "            arr_rel = (row['ETA_FULL'] - global_start).total_seconds() / 3600.0\n",
    "            \n",
    "            # Processing Time & Due Date\n",
    "            if pd.notna(row['ETD_FULL']):\n",
    "                # Normal Port: Due Date = Original ETD\n",
    "                proc_time = (row['ETD_FULL'] - row['ETA_FULL']).total_seconds() / 3600.0\n",
    "                due_date_rel = (row['ETD_FULL'] - global_start).total_seconds() / 3600.0\n",
    "            else:\n",
    "                # Last Port: No processing, Due Date = Original ETA\n",
    "                proc_time = 0.0\n",
    "                due_date_rel = arr_rel \n",
    "            \n",
    "            jssp_rows.append({\n",
    "                'Job_ID': job_map[job_key],\n",
    "                'Job_Label': job_key,\n",
    "                'Operation_Seq': seq,\n",
    "                'Machine_ID': row['Machine_ID'],\n",
    "                'Port_Label': row['PELABUHAN'],\n",
    "                'Arrival_Time': round(arr_rel, 2),\n",
    "                'Proc_Time': max(0.0, round(proc_time, 2)),\n",
    "                'Due_Date': round(due_date_rel, 2),\n",
    "            })\n",
    "            seq += 1\n",
    "    \n",
    "    final_df = pd.DataFrame(jssp_rows)  \n",
    "    final_df = final_df.sort_values(by=['Job_ID', 'Operation_Seq'])\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(f\"Data tersimpan di {output_path}\")\n",
    "\n",
    "preprocess_jssp_tardiness('/home/re1jie/TA-code/JSSP-CAOA-SSR/Data/testcase.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-ta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
